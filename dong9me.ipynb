{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train = pd.read_csv('PJT002_train.csv', parse_dates=[\"dt_of_athrztn\"])\n",
    "val = pd.read_csv('PJT002_validation.csv', parse_dates=[\"dt_of_athrztn\"])\n",
    "test = pd.read_csv('PJT002_test.csv', parse_dates=[\"dt_of_athrztn\"])\n",
    "sub = pd.read_csv('PJT002_submission.csv')\n",
    "\n",
    "train.head()\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)\n",
    "print(sub.shape)\n",
    "\n",
    "train.columns.values\n",
    "\n",
    "val.columns.values\n",
    "\n",
    "list(train.columns.values).sort() == list(val.columns.values).sort()\n",
    "\n",
    "train.isna().sum()\n",
    "\n",
    "train.info(True)\n",
    "\n",
    "binary_y = {'N': 0, 'Y': 1}\n",
    "\n",
    "train['fr_yn'] = train['fr_yn'].map(binary_y)\n",
    "val['fr_yn'] = val['fr_yn'].map(binary_y)\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "## Part 1\n",
    "\n",
    "### bldng_us 건물용도\n",
    "\n",
    "train[\"bldng_us\"].head()\n",
    "\n",
    "train[\"bldng_us\"].unique()\n",
    "\n",
    "test[\"bldng_us\"].unique()\n",
    "\n",
    "train[train[\"bldng_us\"].isnull()].shape\n",
    "\n",
    "test[test[\"bldng_us\"].isnull()].shape\n",
    "\n",
    "pd.value_counts(train[\"bldng_us\"].values.flatten())\n",
    "\n",
    "pd.value_counts(test[\"bldng_us\"].values.flatten())\n",
    "\n",
    "pd.pivot_table(train, index=\"bldng_us\", values=\"fr_yn\")\n",
    "\n",
    "pd.value_counts(train[train[\"bldng_us\"]=='단독주택'][\"bldng_archtctr\"].values.flatten())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#bldng_us_columns = set(train[\"bldng_us\"].unique()).intersection(set(test[\"bldng_us\"].unique())).intersection(set(val[\"bldng_us\"].unique()))\n",
    "\n",
    "\n",
    "\n",
    "#bldng_us_columns = list(train[\"bldng_us\"].unique())\n",
    "\n",
    "#for b in bldng_us_columns:\n",
    "#    if (train[\"bldng_us\"].values == b).sum() < 150:\n",
    "#        train.loc[train[\"bldng_us\"].values == b, \"bldng_us\"] = None\n",
    "#        val.loc[val[\"bldng_us\"].values == b, \"bldng_us\"] = None\n",
    "#        test.loc[test[\"bldng_us\"].values == b, \"bldng_us\"] = None\n",
    "\n",
    "train[\"bldng_us\"].value_counts()\n",
    "\n",
    "pd.pivot_table(train, index=\"bldng_us\", values=\"fr_yn\")\n",
    "\n",
    "# 근린생활시설은 1종,2종 간 용도 차이가 너무 커 제외한다. (val로 검증 완료)\n",
    "\n",
    "train.loc[train[\"bldng_us\"].values == \"제1종근린생활시설\", \"bldng_us\"] = None\n",
    "train.loc[train[\"bldng_us\"].values == \"제2종근린생활시설\", \"bldng_us\"] = None\n",
    "\n",
    "\n",
    "val.loc[val[\"bldng_us\"].values == \"제1종근린생활시설\", \"bldng_us\"] = None\n",
    "val.loc[val[\"bldng_us\"].values == \"제2종근린생활시설\", \"bldng_us\"] = None\n",
    "\n",
    "\n",
    "test.loc[test[\"bldng_us\"].values == \"제1종근린생활시설\", \"bldng_us\"] = None\n",
    "test.loc[test[\"bldng_us\"].values == \"제2종근린생활시설\", \"bldng_us\"] = None\n",
    "\n",
    "\n",
    "one_hot_bldng_us = pd.get_dummies(train[\"bldng_us\"])\n",
    "train = train.join(one_hot_bldng_us)\n",
    "\n",
    "one_hot_bldng_us = pd.get_dummies(val[\"bldng_us\"])\n",
    "val = val.join(one_hot_bldng_us)\n",
    "\n",
    "one_hot_bldng_us = pd.get_dummies(test[\"bldng_us\"])\n",
    "test = test.join(one_hot_bldng_us)\n",
    "\n",
    "#원랜해야하는데 하니까 점수 더 내려감..\n",
    "#train = train.drop(\"bldng_us\", 1)\n",
    "#val = val.drop(\"bldng_us\", 1)\n",
    "#test = test.drop(\"bldng_us\", 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train.columns.values\n",
    "\n",
    "list(train.columns.values).sort() == list(val.columns.values).sort()\n",
    "\n",
    "for a in train.columns.values:\n",
    "    if a not in list(test.columns.values):\n",
    "        print(a)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### bldng_archtctr 건물구조\n",
    "\n",
    "train[\"bldng_archtctr\"].head()\n",
    "\n",
    "train[\"bldng_archtctr\"].unique()\n",
    "\n",
    "test[\"bldng_archtctr\"].unique()\n",
    "\n",
    "for i in train[\"bldng_archtctr\"].unique():\n",
    "    if i not in test[\"bldng_archtctr\"].unique():\n",
    "        print(i)\n",
    "\n",
    "for i in train[\"bldng_archtctr\"].unique():\n",
    "    if i not in val[\"bldng_archtctr\"].unique():\n",
    "        print(i)\n",
    "\n",
    "print(train[train[\"bldng_archtctr\"].isnull()].shape)\n",
    "print(val[val[\"bldng_archtctr\"].isnull()].shape)\n",
    "print(test[test[\"bldng_archtctr\"].isnull()].shape)\n",
    "\n",
    "pd.value_counts(train[\"bldng_archtctr\"].values.flatten())\n",
    "\n",
    "pd.pivot_table(train, index=\"bldng_archtctr\", values=\"fr_yn\")\n",
    "\n",
    "A = [\"목구조\", \"일반목구조\", \"벽돌구조\", \"블록구조\", \"석구조\", \"조적구조\"]\n",
    "B = [\"강파이프구조\", \"경량철골구조\", \"기타강구조\", \"기타구조\", \"기타조적구조\"]\n",
    "C = [\"일반철골구조\", \"철골철근콘크리트구조\", \"철골콘크리트구조\", \"철근콘크리트구조\"]\n",
    "\n",
    "for i in A:\n",
    "    train.loc[train[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"A\"\n",
    "\n",
    "for i in B:\n",
    "    train.loc[train[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"B\"\n",
    "    \n",
    "for i in C:\n",
    "    train.loc[train[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"C\"\n",
    "\n",
    "    \n",
    "for i in A:\n",
    "    val.loc[val[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"A\"\n",
    "\n",
    "for i in B:\n",
    "    val.loc[val[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"B\"\n",
    "    \n",
    "for i in C:\n",
    "    val.loc[val[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"C\"\n",
    "\n",
    "\n",
    "for i in A:\n",
    "    test.loc[test[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"A\"\n",
    "\n",
    "for i in B:\n",
    "    test.loc[test[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"B\"\n",
    "    \n",
    "for i in C:\n",
    "    test.loc[test[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"C\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.pivot_table(train, index=\"bldng_archtctr_encoded\", values=\"fr_yn\")\n",
    "\n",
    "#bldng_archtctr_columns = list(train[\"bldng_archtctr\"].unique())\n",
    "\n",
    "#for b in bldng_archtctr_columns:\n",
    "#    if (train[\"bldng_archtctr\"].values == b).sum() < 150:\n",
    "#        train.loc[train[\"bldng_archtctr\"].values == b, \"bldng_archtctr\"] = None\n",
    "#        val.loc[val[\"bldng_archtctr\"].values == b, \"bldng_archtctr\"] = None\n",
    "#        test.loc[test[\"bldng_us\"].values == b, \"bldng_archtctr\"] = None\n",
    "\n",
    "one_hot_bldng_archtctr = pd.get_dummies(train[\"bldng_archtctr_encoded\"])\n",
    "train = train.join(one_hot_bldng_archtctr)\n",
    "\n",
    "one_hot_bldng_archtctr = pd.get_dummies(val[\"bldng_archtctr_encoded\"])\n",
    "val = val.join(one_hot_bldng_archtctr)\n",
    "\n",
    "one_hot_bldng_archtctr = pd.get_dummies(test[\"bldng_archtctr_encoded\"])\n",
    "test = test.join(one_hot_bldng_archtctr)\n",
    "\n",
    "\n",
    "train = train.drop(\"bldng_archtctr\", 1)\n",
    "val = val.drop(\"bldng_archtctr\", 1)\n",
    "test = test.drop(\"bldng_archtctr\", 1)\n",
    "\n",
    "train = train.drop(\"bldng_archtctr_encoded\", 1)\n",
    "val = val.drop(\"bldng_archtctr_encoded\", 1)\n",
    "test = test.drop(\"bldng_archtctr_encoded\", 1)\n",
    "\n",
    "### bldng_cnt 건물채수\n",
    "\n",
    "train[\"bldng_cnt\"].head()\n",
    "\n",
    "train[\"bldng_cnt\"].value_counts()\n",
    "\n",
    "train[\"bldng_cnt\"].describe()\n",
    "\n",
    "bldng_cnt_under10 = train[train[\"bldng_cnt\"]<10] \n",
    "bldng_cnt_under10[\"bldng_cnt\"].describe()\n",
    "\n",
    "bldng_cnt_under10[\"fr_yn\"].describe()\n",
    "\n",
    "plt.hist(bldng_cnt_under10[\"bldng_cnt\"], rwidth=0.9)\n",
    "\n",
    "sns.countplot(data=bldng_cnt_under10, x=\"bldng_cnt\",hue=\"fr_yn\")\n",
    "\n",
    "pd.pivot_table(bldng_cnt_under10, index=\"bldng_cnt\", values=\"fr_yn\")\n",
    "\n",
    "bldng_cnt_under20 = train[train[\"bldng_cnt\"]<20]\n",
    "bldng_cnt_under20[\"bldng_cnt\"].describe()\n",
    "\n",
    "sns.countplot(data=bldng_cnt_under20, x=\"bldng_cnt\",hue=\"fr_yn\")\n",
    "\n",
    "pd.pivot_table(bldng_cnt_under20, index=\"bldng_cnt\", values=\"fr_yn\")\n",
    "\n",
    "bldng_cnt_under50 = train[train[\"bldng_cnt\"]<50]\n",
    "bldng_cnt_under50[\"bldng_cnt\"].describe()\n",
    "\n",
    "pd.pivot_table(bldng_cnt_under50, index=\"bldng_cnt\", values=\"fr_yn\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bldng_cnt_over50_under250 = train[(train[\"bldng_cnt\"]>50)&(train[\"bldng_cnt\"]<250)]\n",
    "bldng_cnt_over50_under250[\"bldng_cnt\"].describe()\n",
    "\n",
    "bldng_cnt_over50_under250[\"fr_yn\"].describe()\n",
    "\n",
    "plt.scatter(bldng_cnt_over50_under250[\"bldng_cnt\"], bldng_cnt_over50_under250[\"fr_yn\"], s=50)\n",
    "\n",
    "bldng_cnt_over50_under75 = train[(train[\"bldng_cnt\"]>50)&(train[\"bldng_cnt\"]<75)]\n",
    "bldng_cnt_over50_under75[\"fr_yn\"].describe()\n",
    "\n",
    "train.loc[train[\"bldng_cnt\"]<11, \"bldng_cnt_encoded\"] = \"small\"\n",
    "train.loc[(train[\"bldng_cnt\"]>10)&(train[\"bldng_cnt\"]<75), \"bldng_cnt_encoded\"] = \"middle\"\n",
    "train.loc[train[\"bldng_cnt\"]>74, \"bldng_cnt_encoded\"] = \"big\"\n",
    "\n",
    "sns.countplot(data=train, x=\"bldng_cnt_encoded\",hue=\"fr_yn\")\n",
    "\n",
    "\n",
    "\n",
    "one_hot_bldng_cnt_encoded = pd.get_dummies(train[\"bldng_cnt_encoded\"])\n",
    "train = train.join(one_hot_bldng_cnt_encoded)\n",
    "\n",
    "val.loc[val[\"bldng_cnt\"]<11, \"bldng_cnt_encoded\"] = \"small\"\n",
    "val.loc[(val[\"bldng_cnt\"]>10)&(val[\"bldng_cnt\"]<75), \"bldng_cnt_encoded\"] = \"middle\"\n",
    "val.loc[val[\"bldng_cnt\"]>74, \"bldng_cnt_encoded\"] = \"big\"\n",
    "\n",
    "one_hot_bldng_cnt_encoded = pd.get_dummies(val[\"bldng_cnt_encoded\"])\n",
    "val = val.join(one_hot_bldng_cnt_encoded)\n",
    "\n",
    "test.loc[val[\"bldng_cnt\"]<11, \"bldng_cnt_encoded\"] = \"small\"\n",
    "test.loc[(test[\"bldng_cnt\"]>10)&(test[\"bldng_cnt\"]<75), \"bldng_cnt_encoded\"] = \"middle\"\n",
    "test.loc[test[\"bldng_cnt\"]>74, \"bldng_cnt_encoded\"] = \"big\"\n",
    "\n",
    "one_hot_bldng_cnt_encoded = pd.get_dummies(test[\"bldng_cnt_encoded\"])\n",
    "test = test.join(one_hot_bldng_cnt_encoded)\n",
    "\n",
    "train = train.drop(\"bldng_cnt\", 1)\n",
    "val = val.drop(\"bldng_cnt\", 1)\n",
    "test = test.drop(\"bldng_cnt\", 1)\n",
    "\n",
    "train = train.drop(\"bldng_cnt_encoded\", 1)\n",
    "val = val.drop(\"bldng_cnt_encoded\", 1)\n",
    "test = test.drop(\"bldng_cnt_encoded\", 1)\n",
    "\n",
    "\n",
    "\n",
    "### bldng_ar & ttl_ar & lnd_ar 건물건축면적, 건물연면적, 토지면적\n",
    "\n",
    "# val 값이 전처리 하기 전이 조금 더 잘나옴\n",
    "\n",
    "train[\"bldng_ar\"].head(10)\n",
    "\n",
    "print(train[train[\"bldng_ar\"].isnull()].shape)\n",
    "print(val[val[\"bldng_ar\"].isnull()].shape)\n",
    "print(test[test[\"bldng_ar\"].isnull()].shape)\n",
    "\n",
    "print(train[train[\"bldng_ar\"]==0].shape)\n",
    "print(val[val[\"bldng_ar\"]==0].shape)\n",
    "print(test[test[\"bldng_ar\"]==0].shape)\n",
    "\n",
    "print(train[train[\"ttl_ar\"]==0].shape)\n",
    "print(val[val[\"ttl_ar\"]==0].shape)\n",
    "print(test[test[\"ttl_ar\"]==0].shape)\n",
    "\n",
    "print(train[train[\"lnd_ar\"]==0].shape)\n",
    "print(val[val[\"lnd_ar\"]==0].shape)\n",
    "print(test[test[\"lnd_ar\"]==0].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bldng_ar_notnull = train[train[\"bldng_ar\"]!=0]\n",
    "sns.lmplot(data=bldng_ar_notnull, x=\"bldng_ar\", y=\"ttl_ar\", hue=\"fr_yn\", fit_reg=False)\n",
    "\n",
    "low_bldng_ar = train[(train[\"bldng_ar\"]<4000)&(train[\"bldng_ar\"]>0)&(train[\"ttl_ar\"]<3000)&(train[\"ttl_ar\"]>0)]\n",
    "low_bldng_ar.shape\n",
    "\n",
    "sns.lmplot(data=low_bldng_ar, x=\"bldng_ar\", y=\"ttl_ar\", hue=\"fr_yn\", fit_reg=False)\n",
    "\n",
    "low_bldng_ar = train[(train[\"bldng_ar\"]<4000)&(train[\"bldng_ar\"]>0)\n",
    "                     &(train[\"ttl_ar\"]<3000)&(train[\"ttl_ar\"]>0)\n",
    "                     &(train[\"lnd_ar\"]<4000)&(train[\"lnd_ar\"]>0)]\n",
    "\n",
    "sns.lmplot(data=low_bldng_ar, x=\"bldng_ar\", y=\"lnd_ar\", hue=\"fr_yn\", fit_reg=False, size=10)\n",
    "\n",
    "sns.lmplot(data=low_bldng_ar, x=\"ttl_ar\", y=\"lnd_ar\", hue=\"fr_yn\", fit_reg=False, size=10)\n",
    "\n",
    "low_low_bldng_ar = train[(train[\"bldng_ar\"]<1500)&(train[\"bldng_ar\"]>0)\n",
    "                     &(train[\"ttl_ar\"]<2000)&(train[\"ttl_ar\"]>0)\n",
    "                     &(train[\"lnd_ar\"]<2000)&(train[\"lnd_ar\"]>0)]\n",
    "low_low_bldng_ar.shape\n",
    "\n",
    "sns.lmplot(data=low_low_bldng_ar, x=\"bldng_ar\", y=\"ttl_ar\", hue=\"fr_yn\", fit_reg=False, size=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train[train[\"bldng_ar\"]==0].shape\n",
    "\n",
    "train[\"bldng_ar\"].describe()\n",
    "\n",
    "train[\"ttl_ar\"].mean()\n",
    "\n",
    "train[\"ttl_ar\"].median()\n",
    "\n",
    "train.loc[train[\"bldng_ar\"]==0, \"bldng_ar\"] = train[\"bldng_ar\"].median()\n",
    "train.loc[train[\"ttl_ar\"]==0, \"ttl_ar\"] = train[\"ttl_ar\"].median()\n",
    "\n",
    "val.loc[val[\"bldng_ar\"]==0, \"bldng_ar\"] = val[\"bldng_ar\"].median()\n",
    "val.loc[val[\"ttl_ar\"]==0, \"ttl_ar\"] = val[\"ttl_ar\"].median()\n",
    "\n",
    "test.loc[test[\"bldng_ar\"]==0, \"bldng_ar\"] = test[\"bldng_ar\"].median()\n",
    "test.loc[test[\"ttl_ar\"]==0, \"ttl_ar\"] = test[\"ttl_ar\"].median()\n",
    "\n",
    "\n",
    "#train[\"floors\"] = train[\"ttl_ar\"] / train[\"bldng_ar\"]\n",
    "#train[\"floors\"].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train = train.drop(\"lnd_ar\", 1)\n",
    "val = val.drop(\"lnd_ar\", 1)\n",
    "test = test.drop(\"lnd_ar\", 1)\n",
    "\n",
    "\n",
    "\n",
    "### dt_of_athrztn 건물승인날짜\n",
    "\n",
    "train[\"dt_of_athrztn\"].head()\n",
    "\n",
    "train[\"year_athrztn\"] = train[\"dt_of_athrztn\"].str[:4]\n",
    "val[\"year_athrztn\"] = val[\"dt_of_athrztn\"].str[:4]\n",
    "test[\"year_athrztn\"]=test[\"dt_of_athrztn\"].str[:4]\n",
    "\n",
    "year_athrztn_notnull = train[(train[\"year_athrztn\"]!=\"nan\")]\n",
    "year_athrztn_YYYY = year_athrztn_notnull[year_athrztn_notnull[\"year_athrztn\"].astype(int)<3000]\n",
    "year_athrztn_YY = year_athrztn_notnull[year_athrztn_notnull[\"year_athrztn\"].astype(int)>3000]\n",
    "year_athrztn_null = train[train[\"year_athrztn\"]==\"nan\"]\n",
    "\n",
    "print(year_athrztn_YYYY.shape)\n",
    "print(year_athrztn_YY.shape)\n",
    "print(year_athrztn_null.shape)\n",
    "\n",
    "year_athrztn_YYYY[\"year_athrztn\"].head()\n",
    "\n",
    "year_athrztn_YY[\"year_athrztn\"].head()\n",
    "\n",
    "year_athrztn_YY[\"year_athrztn\"] = 1900 + year_athrztn_YY[\"dt_of_athrztn\"].str[:2].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "year_athrztn_notnull = year_athrztn_YYYY.append(year_athrztn_YY)\n",
    "year_athrztn_median=year_athrztn_notnull[\"year_athrztn\"].median()\n",
    "year_athrztn_median\n",
    "\n",
    "year_athrztn_null[\"year_athrztn\"]=year_athrztn_median\n",
    "\n",
    "train = year_athrztn_notnull.append(year_athrztn_null)\n",
    "train.shape\n",
    "\n",
    "val.loc[val[\"year_athrztn\"]==\"nan\",\"year_athrztn\"]= val[val[\"year_athrztn\"]!=\"nan\"][\"year_athrztn\"].median()\n",
    "test.loc[test[\"year_athrztn\"]==\"nan\",\"year_athrztn\"]= test[test[\"year_athrztn\"]!=\"nan\"][\"year_athrztn\"].median()\n",
    "\n",
    "train[\"year_athrztn\"] = train[\"year_athrztn\"].astype(int)\n",
    "val[\"year_athrztn\"] = val[\"year_athrztn\"].astype(int)\n",
    "test[\"year_athrztn\"] = test[\"year_athrztn\"].astype(int)\n",
    "\n",
    "\n",
    "train.reset_index(inplace=True)\n",
    "train.drop('index',inplace=True,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train.loc[train[\"year_athrztn\"]<2000,\"year_athrztn_encoded\"] = \"old\"\n",
    "train.loc[train[\"year_athrztn\"]>1999,\"year_athrztn_encoded\"] = \"new\"\n",
    "\n",
    "val.loc[val[\"year_athrztn\"]<2000,\"year_athrztn_encoded\"] = \"old\"\n",
    "val.loc[val[\"year_athrztn\"]>1999,\"year_athrztn_encoded\"] = \"new\"\n",
    "\n",
    "test.loc[test[\"year_athrztn\"]<2000,\"year_athrztn_encoded\"] = \"old\"\n",
    "test.loc[test[\"year_athrztn\"]>1999,\"year_athrztn_encoded\"] = \"new\"\n",
    "\n",
    "pd.pivot_table(train, index=\"year_athrztn_encoded\", values=\"fr_yn\")\n",
    "\n",
    "\n",
    "\n",
    "train = train.drop(\"dt_of_athrztn\", 1)\n",
    "val = val.drop(\"dt_of_athrztn\", 1)\n",
    "test = test.drop(\"dt_of_athrztn\", 1)\n",
    "\n",
    "\n",
    "\n",
    "## part 3\n",
    "\n",
    "### ele_energy_us_YYYYMM 전기 에너지 사용량 (YYYY년 M월)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## part5\n",
    "\n",
    "### trgt_cnt 소방점검대상물기준\n",
    "\n",
    "train[train[\"trgt_crtr\"].notnull()].shape\n",
    "\n",
    "pd.value_counts(train[\"trgt_crtr\"].values.flatten())\n",
    "\n",
    "pd.pivot_table(train, index=\"trgt_crtr\", values=\"fr_yn\")\n",
    "\n",
    "pd.value_counts(test[\"trgt_crtr\"].values.flatten())\n",
    "\n",
    "pd.value_counts(val[\"trgt_crtr\"].values.flatten())\n",
    "\n",
    "pd.value_counts(test[\"trgt_crtr\"].values.flatten())\n",
    "\n",
    "train.loc[train[\"trgt_crtr\"]==\"자동화재탐지설치대상\", \"auto_fr\"] = 1\n",
    "train.loc[train[\"trgt_crtr\"]!=\"자동화재탐지설치대상\", \"auto_fr\"] = 0\n",
    "train.loc[train[\"trgt_crtr\"]==\"옥내소화전설치대상\", \"fireplug\"] = 1\n",
    "train.loc[train[\"trgt_crtr\"]!=\"옥내소화전설치대상\", \"fireplug\"] = 0\n",
    "train.loc[train[\"trgt_crtr\"]==\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 1\n",
    "train.loc[train[\"trgt_crtr\"]!=\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 0\n",
    "\n",
    "\n",
    "val.loc[val[\"trgt_crtr\"]==\"자동화재탐지설치대상\", \"auto_fr\"] = 1\n",
    "val.loc[val[\"trgt_crtr\"]!=\"자동화재탐지설치대상\", \"auto_fr\"] = 0\n",
    "val.loc[val[\"trgt_crtr\"]==\"옥내소화전설치대상\", \"fireplug\"] = 1\n",
    "val.loc[val[\"trgt_crtr\"]!=\"옥내소화전설치대상\", \"fireplug\"] = 0\n",
    "val.loc[val[\"trgt_crtr\"]==\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 1\n",
    "val.loc[val[\"trgt_crtr\"]!=\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 0\n",
    "\n",
    "test.loc[test[\"trgt_crtr\"]==\"자동화재탐지설치대상\", \"auto_fr\"] = 1\n",
    "test.loc[test[\"trgt_crtr\"]!=\"자동화재탐지설치대상\", \"auto_fr\"] = 0\n",
    "test.loc[test[\"trgt_crtr\"]==\"옥내소화전설치대상\", \"fireplug\"] = 1\n",
    "test.loc[test[\"trgt_crtr\"]!=\"옥내소화전설치대상\", \"fireplug\"] = 0\n",
    "test.loc[test[\"trgt_crtr\"]==\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 1\n",
    "test.loc[test[\"trgt_crtr\"]!=\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "train = train.drop(\"trgt_crtr\", 1)\n",
    "val = val.drop(\"trgt_crtr\", 1)\n",
    "test = test.drop(\"trgt_crtr\", 1)\n",
    "\n",
    "\n",
    "\n",
    "### fr_fghtng_fclt_spcl_css_5_yn & fr_fghtng_fclt_spcl_css_6_yn 소방시설특례 5,6호 여부\n",
    "\n",
    "#공란, N, NA로 구성\n",
    "\n",
    "train[train[\"fr_fghtng_fclt_spcl_css_5_yn\"].isnull()].shape\n",
    "\n",
    "train[train[\"fr_fghtng_fclt_spcl_css_5_yn\"].notnull()].shape\n",
    "\n",
    "train[train[\"fr_fghtng_fclt_spcl_css_5_yn\"]==\"N\"].shape\n",
    "\n",
    "test[test[\"fr_fghtng_fclt_spcl_css_5_yn\"].isnull()].shape\n",
    "\n",
    "test[test[\"fr_fghtng_fclt_spcl_css_5_yn\"].notnull()].shape\n",
    "\n",
    "train.loc[train[\"fr_fghtng_fclt_spcl_css_5_yn\"].isnull(),\"css_5_yn_encoded\"]=0\n",
    "train.loc[train[\"fr_fghtng_fclt_spcl_css_5_yn\"].notnull(),\"css_5_yn_encoded\"]=1\n",
    "\n",
    "pd.pivot_table(train, index=\"css_5_yn_encoded\", values=\"fr_yn\")\n",
    "\n",
    "train.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].isnull(),\"css_6_yn_encoded\"]=0\n",
    "train.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].notnull(),\"css_6_yn_encoded\"]=1\n",
    "\n",
    "\n",
    "pd.pivot_table(train, index=\"css_6_yn_encoded\", values=\"fr_yn\")\n",
    "\n",
    "val.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].isnull(),\"css_6_yn_encoded\"]=0\n",
    "val.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].notnull(),\"css_6_yn_encoded\"]=1\n",
    "\n",
    "test.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].isnull(),\"css_6_yn_encoded\"]=0\n",
    "test.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].notnull(),\"css_6_yn_encoded\"]=1\n",
    "\n",
    "\n",
    "\n",
    "train = train.drop(\"fr_fghtng_fclt_spcl_css_5_yn\", 1)\n",
    "val = val.drop(\"fr_fghtng_fclt_spcl_css_5_yn\", 1)\n",
    "test = test.drop(\"fr_fghtng_fclt_spcl_css_5_yn\", 1)\n",
    "\n",
    "train = train.drop(\"fr_fghtng_fclt_spcl_css_6_yn\", 1)\n",
    "val = val.drop(\"fr_fghtng_fclt_spcl_css_6_yn\", 1)\n",
    "test = test.drop(\"fr_fghtng_fclt_spcl_css_6_yn\", 1)\n",
    "\n",
    "train = train.drop(\"css_5_yn_encoded\", 1)\n",
    "\n",
    "\n",
    "\n",
    "### us_yn 사용 여부\n",
    "\n",
    "print(train[train[\"us_yn\"].isnull()].shape)\n",
    "print(train[train[\"us_yn\"].notnull()].shape)\n",
    "print(test[test[\"us_yn\"].isnull()].shape)\n",
    "print(test[test[\"us_yn\"].notnull()].shape)\n",
    "\n",
    "pd.pivot_table(train, index=\"us_yn\", values=\"fr_yn\")\n",
    "\n",
    "pd.value_counts(train[\"us_yn\"].values.flatten())\n",
    "\n",
    "pd.value_counts(test[\"us_yn\"].values.flatten())\n",
    "\n",
    "one_hot_us_yn = pd.get_dummies(train[\"us_yn\"])\n",
    "train = train.join(one_hot_us_yn)\n",
    "\n",
    "one_hot_us_yn = pd.get_dummies(val[\"us_yn\"])\n",
    "val = val.join(one_hot_us_yn)\n",
    "\n",
    "one_hot_us_yn = pd.get_dummies(test[\"us_yn\"])\n",
    "test = test.join(one_hot_us_yn)\n",
    "\n",
    "train = train.drop(\"us_yn\", 1)\n",
    "val = val.drop(\"us_yn\", 1)\n",
    "test = test.drop(\"us_yn\", 1)\n",
    "\n",
    "### dngrs_thng_yn 위험물대상여부\n",
    "\n",
    "print(train[train[\"dngrs_thng_yn\"].isnull()].shape)\n",
    "print(train[train[\"dngrs_thng_yn\"].notnull()].shape)\n",
    "print(test[test[\"dngrs_thng_yn\"].isnull()].shape)\n",
    "print(test[test[\"dngrs_thng_yn\"].notnull()].shape)\n",
    "\n",
    "pd.value_counts(train[\"dngrs_thng_yn\"].values.flatten())\n",
    "\n",
    "pd.value_counts(test[\"dngrs_thng_yn\"].values.flatten())\n",
    "\n",
    "pd.pivot_table(train, index=\"dngrs_thng_yn\", values=\"fr_yn\")\n",
    "\n",
    "train.loc[train[\"dngrs_thng_yn\"].isnull(),\"dngrs_thng_yn_encoded\"]= 0\n",
    "train.loc[train[\"dngrs_thng_yn\"].notnull(),\"dngrs_thng_yn_encoded\"]= 1\n",
    "\n",
    "\n",
    "pd.pivot_table(train, index=\"dngrs_thng_yn_encoded\", values=\"fr_yn\")\n",
    "\n",
    "val.loc[train[\"dngrs_thng_yn\"].isnull(),\"dngrs_thng_yn_encoded\"]= 0\n",
    "val.loc[train[\"dngrs_thng_yn\"].notnull(),\"dngrs_thng_yn_encoded\"]= 1\n",
    "\n",
    "test.loc[train[\"dngrs_thng_yn\"].isnull(),\"dngrs_thng_yn_encoded\"]= 0\n",
    "test.loc[train[\"dngrs_thng_yn\"].notnull(),\"dngrs_thng_yn_encoded\"]= 1\n",
    "\n",
    "train = train.drop(\"dngrs_thng_yn\", 1)\n",
    "val = val.drop(\"dngrs_thng_yn\", 1)\n",
    "test = test.drop(\"dngrs_thng_yn\", 1)\n",
    "\n",
    "\n",
    "\n",
    "### slf_fr_brgd_yn 자체소방대여부\n",
    "\n",
    "print(train[train[\"slf_fr_brgd_yn\"].isnull()].shape)\n",
    "print(train[train[\"slf_fr_brgd_yn\"].notnull()].shape)\n",
    "print(test[test[\"slf_fr_brgd_yn\"].isnull()].shape)\n",
    "print(test[test[\"slf_fr_brgd_yn\"].notnull()].shape)\n",
    "\n",
    "pd.value_counts(train[\"slf_fr_brgd_yn\"].values.flatten())\n",
    "\n",
    "pd.value_counts(test[\"slf_fr_brgd_yn\"].values.flatten())\n",
    "\n",
    "train.loc[train[\"slf_fr_brgd_yn\"].isnull(),\"slf_fr_brgd_yn\"]=0\n",
    "\n",
    "pd.pivot_table(train, index=\"slf_fr_brgd_yn\", values=\"fr_yn\")\n",
    "\n",
    "train = train.drop(\"slf_fr_brgd_yn\", 1)\n",
    "val = val.drop(\"slf_fr_brgd_yn\", 1)\n",
    "test = test.drop(\"slf_fr_brgd_yn\", 1)\n",
    "\n",
    "\n",
    "\n",
    "### blk_dngrs_thng_mnfctr_yn 대량위험물제조소등여부\n",
    "\n",
    "print(train[train[\"blk_dngrs_thng_mnfctr_yn\"].isnull()].shape)\n",
    "print(train[train[\"blk_dngrs_thng_mnfctr_yn\"].notnull()].shape)\n",
    "print(test[test[\"blk_dngrs_thng_mnfctr_yn\"].isnull()].shape)\n",
    "print(test[test[\"blk_dngrs_thng_mnfctr_yn\"].notnull()].shape)\n",
    "\n",
    "pd.value_counts(train[\"blk_dngrs_thng_mnfctr_yn\"].values.flatten())\n",
    "\n",
    "pd.value_counts(test[\"blk_dngrs_thng_mnfctr_yn\"].values.flatten())\n",
    "\n",
    "train.loc[train[\"blk_dngrs_thng_mnfctr_yn\"].isnull(),\"blk_dngrs_thng_mnfctr_yn\"]=0\n",
    "pd.pivot_table(train, index=\"blk_dngrs_thng_mnfctr_yn\", values=\"fr_yn\")\n",
    "\n",
    "train = train.drop(\"blk_dngrs_thng_mnfctr_yn\", 1)\n",
    "val = val.drop(\"blk_dngrs_thng_mnfctr_yn\", 1)\n",
    "test = test.drop(\"blk_dngrs_thng_mnfctr_yn\", 1)\n",
    "\n",
    "\n",
    "\n",
    "### cltrl_hrtg_yn 문화재여부\n",
    "\n",
    "print(train[train[\"cltrl_hrtg_yn\"].isnull()].shape)\n",
    "print(train[train[\"cltrl_hrtg_yn\"].notnull()].shape)\n",
    "print(test[test[\"cltrl_hrtg_yn\"].isnull()].shape)\n",
    "print(test[test[\"cltrl_hrtg_yn\"].notnull()].shape)\n",
    "\n",
    "pd.value_counts(train[\"cltrl_hrtg_yn\"].values.flatten())\n",
    "\n",
    "pd.value_counts(test[\"cltrl_hrtg_yn\"].values.flatten())\n",
    "\n",
    "train = train.drop(\"cltrl_hrtg_yn\", 1)\n",
    "val = val.drop(\"cltrl_hrtg_yn\", 1)\n",
    "test = test.drop(\"cltrl_hrtg_yn\", 1)\n",
    "\n",
    "\n",
    "\n",
    "# Train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = train.drop(['fr_yn', 'dt_of_fr'], 1)\n",
    "y_train = train['fr_yn']\n",
    "X_val = val.drop(['fr_yn', 'dt_of_fr'], 1)\n",
    "y_val = val['fr_yn']\n",
    "test = test.drop(['dt_of_fr'], 1)\n",
    "\n",
    "df_all = pd.concat([X_train, X_val, test])\n",
    "\n",
    "categorical_cols = df_all.select_dtypes(['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df_all[col] = pd.Categorical(df_all[col]).codes\n",
    "\n",
    "X_train = df_all[:len(train)]\n",
    "X_val = df_all[len(train):-len(test)]\n",
    "test = df_all[-len(test):]\n",
    "\n",
    "X_train = X_train.fillna(-1)\n",
    "X_val = X_val.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "f1_score(y_val, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
